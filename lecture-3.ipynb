{
 "metadata": {
  "name": "",
  "signature": "sha256:14565a81470a68e22e8406c7de75d2e0a855881d087685399d5e1493c078abb2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Lecture 3: Scalar product, orthogonality, matrix rank"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Syllabus\n",
      "**Week 2:** Matrices, vectors, norms, ranks\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Recap of the previous lecture\n",
      "- Norms are measures of smallness, used to compute the accuracy\n",
      "- Definition of $1$, $p$ and Euclidean norms\n",
      "- Matrix norms\n",
      "- $L$_1 norm is used in compressed sensing as a surrogate for sparsity."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Today lecture\n",
      "Today we will talk about:\n",
      "- Scalar products and unitary (orthogonal) matrices\n",
      "- Rank of the matrix\n",
      "- Singular value decomposition (SVD) and low-rank approximation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scalar product\n",
      "If norm is a measure of distances, then the scalar product take angle into account.  \n",
      "The scalar product is defined as\n",
      "$$\n",
      "   (x, y) = \\sum_{i=1}^n \\overline{x}_i y_i,\n",
      "$$\n",
      "where $\\overline{x}$ denotes the *complex conjugate* of $x$. The Euclidean norm is then\n",
      "$$\n",
      "   \\Vert x \\Vert^2 = (x, x),\n",
      "$$\n",
      "or it is said the the norm is **induced** by matrix products.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Remark** For the angle between two vectors is defined as\n",
      "$$\n",
      "   \\cos \\phi = \\frac{(x, y)}{\\Vert x \\Vert \\Vert y \\Vert} \n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An important property of the scalar product is the **Cauchy-Bunyakovski inequality**:\n",
      "$$\n",
      "    (x, y) \\leq \\Vert x \\Vert \\Vert y \\Vert,\n",
      "$$\n",
      "and thus the angle between two vectors is defined properly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The scalar product can be written as a matrix-by-matrix product  \n",
      "$$\n",
      "  (x, y) = x^* y,\n",
      "$$\n",
      "where $^*$ is a **conjugate transpose** of the matrix:  \n",
      "$$\n",
      "B = A^*, \\quad B_{ij} = \\overline{A_{ji}}.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Norm conservation\n",
      "For stability it is really important that the error do not grow. Suppose that you approximately get a vector,  \n",
      "$$\n",
      "  \\Vert x - \\widehat{x} \\Vert \\leq \\varepsilon.\n",
      "$$\n",
      "Then the final result is (some) linear transformation of $x$:  \n",
      "$$\n",
      "   y = Ux, \\quad \\widehat{y} = U \\widehat{x}.\n",
      "$$\n",
      "If we want to estimate a difference between $\\widehat{y}$ and $y$:  \n",
      "$$\n",
      "   \\Vert y - \\widehat{y} \\Vert = \\Vert U ( x - \\widehat{x}) \\Vert \\leq \\Vert U \\Vert \\varepsilon.\n",
      "$$\n",
      "The question is for which kind of matrices the length of the vector **will not change**. For the euclidean norm this produces a very important class of matrices: **unitary** (or orthogonal in the real case) matrices."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unitary (orthogonal) matrices\n",
      "Let $U$ be an $n \\times r$ matrix, and $\\Vert U z \\Vert = \\Vert z \\Vert$ for all $z$. This can happen if and only if  \n",
      "$$\n",
      "   U^* U = I,\n",
      "$$\n",
      "where $I$ is an **identity matrix**\n",
      "Indeee, $$\\Vert Uz \\Vert^2 = (Uz, Uz) = (Uz)^* Uz = z^* (U^* U) z = z^* z,$$ \n",
      "which can also hold if $U^* U = I$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Unitary matrices\n",
      "In the real case, when $U^* = U^{\\top}$, the matrix is called orthogonal.  \n",
      "Are there many unitary matrices? First of all, a product of two unitary matrices is a unitary matrix:  \n",
      "$$(UV)^* UV = V^* (U^* U) V = V^* V = I,$$\n",
      "thus if we give some non-trivial examples of unitary matrices, we will be able to get any unitary transformation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Examples of unitary matrices\n",
      "There are two important classes of unitary matrices:\n",
      "1. Householder matrices\n",
      "2. Givens (Jacobi) matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Householder matrices\n",
      "Householder matrix is the matrix of the form  \n",
      "$$H = I - 2 vv^*,$$\n",
      "where $u$ is an $n \\times 1$ matrix and $v^* v = I$. Can you show that $H$ is unitary?  It is also a reflection. <img src=\"householder.jpeg\">  \n",
      "A simple proof: $H^* H = (I - 2 vv^*)(I - 2 v v^*) = I$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Givens(Jacobi) matrix\n",
      "A Givens matrix is a matrix  \n",
      "$$\n",
      "    A = \\begin{bmatrix}\n",
      "          \\cos \\alpha & \\sin \\alpha \\\\\n",
      "          -\\sin \\alpha & \\cos \\alpha\n",
      "        \\end{bmatrix},\n",
      "$$\n",
      "which is a rotation. For a general case, we select two $(i, j)$ planes and rotate only in those:\n",
      "$$\n",
      "    x'_i = \\cos \\alpha x_i + \\sin \\alpha x_j, \\quad x'_j = -\\sin \\alpha x_i + \\cos\\alpha x_j,\n",
      "$$\n",
      "with all other $x_i$ remain unchanged."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Summary on unitary matrices\n",
      "- Unitary matrices preserve the norm\n",
      "- There are two \"basic\" classes of unitary matrices, Householder and Givens.\n",
      "- Every unitary matrix can be represented as a product of those."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Matrix and linear spaces\n",
      "A matrix can be considered as a sequence of vectors, its columns:\n",
      "$$\n",
      "   A = [a_1, \\ldots, a_m], \n",
      "$$\n",
      "where $a_m \\in \\mathbb{C}^n$.  \n",
      "A matrix-by-vector product is equivalent to taking a linear combination of those vectors  \n",
      "$$\n",
      "   y =  Ax, \\quad \\Longleftrightarrow y = a_1 x_1 + a_2 x_2 + \\ldots +a_m x_m.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Linear dependence\n",
      "The vectors are called linearly dependent, if there exist non-zero coefficients $x_i$ such that\n",
      "$$\\sum_i a_i x_i = 0,$$\n",
      "or in the matrix form,\n",
      "$$\n",
      "   Ax = 0, \\quad \\Vert x \\Vert \\ne 0.\n",
      "$$\n",
      "In this case, we say that the matrix $A$ has non-trivial **nullspace**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Dimension of a linear space\n",
      "A **linear space** is defined as all possible vectors of the form \n",
      "$$\n",
      "   \\sum_{i=1}^m a_i x_i, \n",
      "$$\n",
      "where $x_i$ are some coefficients and $a_i, i = 1, \\ldots, m$ are given vectors. In the matrix form, the linear space is a collection of the vectors of the form  \n",
      "$$A x.$$\n",
      "This set is also called the **range** of the matrix.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Matrix rank\n",
      "What is a matrix rank?  A matrix rank is defined as the maximal number of linearly independent columns in a matrix, or the **dimension of its column space**.  \n",
      "You can also use linear combination of rows to define the rank.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Theorem**  \n",
      "The dimension of the column space of the matrix is equal to the dimension of the row space of the matrix."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Skeleton decomposition\n",
      "A very useful representation for computation of the matrix rank is the **skeleton decomposition**, which can be graphically represented as follows:  \n",
      "<img src=\"cross-pic.png\">\n",
      "or in the matrix form\n",
      "$$\n",
      "   A = U \\widehat{A}^{-1} V^{\\top},\n",
      "$$\n",
      "where $U$ are some $r$ columns of $A$, $V^{\\top}$ are some rows of $A$, $\\widehat{A}$ is the submatrix on the intersection, which should be **nonsingular**.\n",
      "\n",
      "**Remark.**  \n",
      "An inverse of the matrix $P$ the matrix $Q = P^{-1}$ such that  \n",
      "$ P Q = QP = I$.  \n",
      "If the matrix is square and has full rank (i.e. equal to $n$) then the inverse exists."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Proof for the skeleton decomposition\n",
      "Let $U$ be the $r$ columns based on the submatrix $\\widehat{A}$. Then they are linearly independent. Take any other column $u$ of $A$. Then it is a linear combination of the columns of $U$, i.e.  \n",
      "$u = U x$.  \n",
      "These are $n$ equations. We take $r$ of those corresponding to the rows that contain $\\widehat{A}$ and get the equation  \n",
      "$$\\widehat{u} = \\widehat{A} x,$$  therefore  \n",
      "$$x = \\widehat{A}^{-1} \\widehat{u},$$ and that gives us the result."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A closer look\n",
      "Any rank-$r$ matrix can be written in the form\n",
      "$$A = U \\widehat{A}^{-1} V^{\\top},$$\n",
      "where $U$ is $n \\times r$, $V$ is $m \\times r$ and $\\widehat{A}$ is $r \\times r$, or \n",
      "$$\n",
      "   A = U' V'^{\\top}.\n",
      "$$\n",
      "So, every rank-$r$ matrix can be written as a product of a \"tall\" matrix $U'$ by a long matrix $V'$. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the index form, it is  \n",
      "$$\n",
      "   a_{ij} = \\sum_{\\alpha=1}^r u_{i \\alpha} v_{j \\alpha}.\n",
      "$$\n",
      "For rank 1 we have\n",
      "$$\n",
      "   a_{ij} = u_i v_j,\n",
      "$$\n",
      "i.e. it is a separation of indices and rank-$r$ is a sum of rank-$1$ matrices!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Storage\n",
      "It is interesting to note, that for the rank-$r$ matrix only $U$ and $V$ can be stored, which gives us $(n+m) r$ parameters, so it can be used for compression. We can also compute matrix-by-vector product much faster."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "n = 1000\n",
      "r = 10\n",
      "u = np.random.randn(n, r)\n",
      "v = np.random.randn(n, r)\n",
      "a = u.dot(v.T)\n",
      "x = np.random.randn(n)\n",
      "%timeit a.dot(x)\n",
      "%timeit u.dot(v.T.dot(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 674 \u00b5s per loop\n",
        "10000 loops, best of 3: 14.8 \u00b5s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Computing matrix rank\n",
      "import numpy as np\n",
      "n = 50 \n",
      "a = np.ones((n, n))\n",
      "print 'Rank of the matrix:', np.linalg.matrix_rank(a)\n",
      "b = a + 0 * np.random.randn(n, n)\n",
      "print 'Rank of the matrix:', np.linalg.matrix_rank(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rank of the matrix: 1\n",
        "Rank of the matrix: 1\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Instability of the matrix rank\n",
      "For any rank-$r$ matrix $A$ with $r < \\min(m, n)$ there is a matrix $B$ such that its rank rank is equal to $\\min(m, n)$ and\n",
      "$$\n",
      " \\Vert A - B \\Vert = \\varepsilon.\n",
      "$$\n",
      "So, does this mean that numerically matrix rank has no meaning? (I.e., small perturbations lead to full rank)!  \n",
      "The solution is to compute the best **rank-r** approximation to a matrix."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Singular value decomposition\n",
      "To compute low-rank approximation, we need to compute **singular value decomposition**.  \n",
      "Any matrix $A$ can be written as a product of three matrices:  \n",
      "$$\n",
      "   A = U \\Sigma V^*,\n",
      "$$\n",
      "where $U$ is an $n \\times K$ unitary matrix, $V$ is an $m \\times K$ unitary matrix, $K = \\min(m, n)$ $\\Sigma$ is a diagonal matrix with non-negative elements $\\sigma_1 \\geq  \\ldots, \\geq \\sigma_K$ on the diagonal. \n",
      "\n",
      "Computation of the best rank-$r$ approximation is equivalent to setting $\\sigma_{r+1}= 0, \\ldots, \\sigma_K = 0$. The error is then determined by the omitted singular value!  \n",
      "$$\n",
      "   \\min_{A_r} \\Vert A - A_r \\Vert = \\sigma_{r+1},\n",
      "$$\n",
      "that is why it is important to look at the decay of the singular vectors."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Low-rank approximation via SVD\n",
      "$\\Vert A - A_r \\Vert = \\Vert U \\Sigma V^* - A_r \\Vert = \\Vert \\Sigma - U^* A_r V \\Vert$,  \n",
      "where we used that for spectral norm (and for the Frobenius as well) we have  \n",
      "\n",
      "$$\\Vert X Q \\Vert = \\Vert X \\Vert$$\n",
      "for any unitary $Q$ and  any matrix $X$. This is called **unitary equivalence** of the spectral norm (and Frobenius as well).  \n",
      "What is left is to note that the best rank-$r$ approximation of the diagonal matrix is its subdiagonal.  \n",
      "Computing the SVD is tricky; we will talk about the algorithms hidden in this computation later. But we already can do this in Python!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Computing matrix rank\n",
      "import numpy as np\n",
      "n = 50 \n",
      "a = np.ones((n, n))\n",
      "print 'Rank of the matrix:', np.linalg.matrix_rank(a)\n",
      "b = a + 1e-5 * np.random.randn(n, n)\n",
      "print 'Rank of the matrix:', np.linalg.matrix_rank(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rank of the matrix: 1\n",
        "Rank of the matrix: 50\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u, s, v = np.linalg.svd(b)\n",
      "print s[1]/s[0]\n",
      "r = 1\n",
      "u1 = u[:, :r]\n",
      "s1 = s[:r]\n",
      "v1 = v[:r, :]\n",
      "a1 = u1.dot(np.diag(s1).dot(v1))\n",
      "print np.linalg.norm(a - a1)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.79817259973e-06\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0.00010846855849342956"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can do something more interesting, like function approximation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import prettyplotlib as ppl\n",
      "n = 1000\n",
      "a = [[1.0/(i+j+1) for i in xrange(n)] for j in xrange(n)] #Hilbert matrix \n",
      "a = np.array(a)\n",
      "u, s, v = np.linalg.svd(a)\n",
      "fig, ax = ppl.subplots(1, 1)\n",
      "ax.semilogy(s[1:30])\n",
      "#We have very good low-rank approximation of it!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10f813a50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERERERERERGA/w8f/Jy6Dv6RogAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10ee42950>"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Linear factor analysis & low-rank\n",
      "Consider a linear factor model, \n",
      "\n",
      "$$y = Ax, $$ where $y$ is a vector of length $n$, and $x$ is a vector of length $r$.  \n",
      "The data is organizes as samples: we observe vectors  \n",
      "$$y_1, \\ldots, y_T,$$\n",
      "then the factor model can be written as  \n",
      "$$\n",
      "  Y = AX,\n",
      "$$\n",
      "where $Y$ is $n \\times T$, $A$ is $n \\times r$ and $X$ is $r \\times T$. This is exactly a rank-$r$ model: it tells us that the vector lie in a small subspace!  \n",
      "We also can use SVD to recover this subspace (but not the independent components)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Questions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:80%;\n",
        "        margin-left:auto !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'Fenix', serif;\n",
        "    }\n",
        "    h3{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "\th4{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "       }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\t   \n",
        "    div.text_cell_render{\n",
        "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 1.2;\n",
        "        font-size: 160%;\n",
        "        width:70%;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\";\n",
        "\t\t\tfont-size: 90%;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 50pt;\n",
        "\t\tline-height: 100%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\t\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x104335990>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}