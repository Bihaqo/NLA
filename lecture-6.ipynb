{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:079301358d6d6631455e8faf43266d4d2776b2bbb2ca608c49f835170f0036d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Lecture 6: Matrix decompositions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Syllabus\n",
      "**Week 1:** Python intro  \n",
      "**Week 2:** Matrices, vectors, norms, ranks  \n",
      "**Week 3:** Linear systems, eigenvectors, eigenvalues\n",
      "**Week 4:** Matrix decompositions: LU, QR, SVD + test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Recap of the previous lecture\n",
      "- Eigenvectors and their applications (Schrodinger + PageRank)\n",
      "- Gershgorin circles\n",
      "- Computing eigenvectors using power method, $x := Ax$\n",
      "- Schur theorem, $A = U T U^*$\n",
      "- Normal matrices $AA^* = A^* A$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Today lecture\n",
      "Today we will talk about the matrix factorizations\n",
      "- LU decomposition and Gaussian diagonalization\n",
      "- QR decomposition and Gram-Schmidt orthogonalization\n",
      "- SVD and low-rank approximation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##What is the LU factorization\n",
      "\n",
      "From the title, it is clear, that LU factorization is the representation of a given matrix $A$ as a product  \n",
      "of a **lower triangular matrix** $L$ and an **upper triangular** matrix $U$.  \n",
      "The matrix $L$ has to be non-singular with ones on the diagonal, and the matrix $U$ has to be non-singular.  \n",
      "\n",
      "**Main goal** of the LU decomposition is to solve linear systems, because\n",
      "$$\n",
      "    A^{-1} f = (L U)^{-1} f = U^{-1} L^{-1} f, \n",
      "$$\n",
      "and this reduces to the solution of a linear system \n",
      "$$\n",
      "     L y = f, \n",
      "$$\n",
      "and \n",
      "$$\n",
      "   U x = y.\n",
      "$$\n",
      "Solving linear systems with triangular matrices is **easy**: you just solve the equation with one unknown, put into the second equation, and so on. The computational cost of such algorithm in $\\mathcal{O}(n^2)$ arithmetic operations, once $LU$ factorization is known. \n",
      "\n",
      "Note that the inverse of triangular matrix is a triangular matrix.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## LU decomposition: the algorithm\n",
      "We can do some **symbolic computations** using the Python sympy package for our Hilbert matrix, to illustrate how LU decomposition looks like."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import sympy\n",
      "from sympy.matrices import Matrix\n",
      "import IPython\n",
      "sympy.init_printing(use_latex=True)\n",
      "n = 5\n",
      "w = Matrix(n, n, lambda i, j: 1/(i + j +  sympy.Integer(1)/2))\n",
      "L, U, tmp = w.LUdecomposition()\n",
      "#Generate the final expression\n",
      "expr = (L + U)\n",
      "fn = '%s \\\\times %s = %s' % (sympy.latex(L), sympy.latex(U), sympy.latex(w))\n",
      "IPython.display.Math(fn)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "latex": [
        "$$\\left[\\begin{matrix}1 & 0 & 0 & 0 & 0\\\\\\frac{1}{3} & 1 & 0 & 0 & 0\\\\\\frac{1}{5} & \\frac{6}{7} & 1 & 0 & 0\\\\\\frac{1}{7} & \\frac{5}{7} & \\frac{15}{11} & 1 & 0\\\\\\frac{1}{9} & \\frac{20}{33} & \\frac{210}{143} & \\frac{28}{15} & 1\\end{matrix}\\right] \\times \\left[\\begin{matrix}2 & \\frac{2}{3} & \\frac{2}{5} & \\frac{2}{7} & \\frac{2}{9}\\\\0 & \\frac{8}{45} & \\frac{16}{105} & \\frac{8}{63} & \\frac{32}{297}\\\\0 & 0 & \\frac{128}{11025} & \\frac{128}{8085} & \\frac{256}{15015}\\\\0 & 0 & 0 & \\frac{512}{693693} & \\frac{2048}{1486485}\\\\0 & 0 & 0 & 0 & \\frac{32768}{703956825}\\end{matrix}\\right] = \\left[\\begin{matrix}2 & \\frac{2}{3} & \\frac{2}{5} & \\frac{2}{7} & \\frac{2}{9}\\\\\\frac{2}{3} & \\frac{2}{5} & \\frac{2}{7} & \\frac{2}{9} & \\frac{2}{11}\\\\\\frac{2}{5} & \\frac{2}{7} & \\frac{2}{9} & \\frac{2}{11} & \\frac{2}{13}\\\\\\frac{2}{7} & \\frac{2}{9} & \\frac{2}{11} & \\frac{2}{13} & \\frac{2}{15}\\\\\\frac{2}{9} & \\frac{2}{11} & \\frac{2}{13} & \\frac{2}{15} & \\frac{2}{17}\\end{matrix}\\right]$$"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "<IPython.core.display.Math at 0x104337cd0>"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "A simple implementation of the LU factorization can be done in 3 cycles:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "L = Matrix(n, n, lambda i, j: 0)\n",
      "U = Matrix(n, n, lambda i, j: 0)\n",
      "a = w.copy() #Our matrix\n",
      "for k in xrange(n): #Eliminate one row\n",
      "    \n",
      "    L[k, k] = 1\n",
      "    for i in xrange(k+1, n):\n",
      "        L[i, k] = a[i, k] / a[k, k]\n",
      "        for j in xrange(k+1, n):\n",
      "            a[i, j] = a[i, j] - L[i, k] * a[k, j]\n",
      "    for j in xrange(k, n):\n",
      "        U[k, j] = a[k, j]\n",
      "        \n",
      "            "
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Strictly regular matrices and LU decomposition \n",
      "A matrix $A$ is strictly regular, if all of its **principal minors** (i.e, submatrices in the first $k$ rows and $k$ columns) are non-singular. In this case, there always exists a LU-decomposition.  The reverse is also true. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**Proof**. If there is a LU-decomposition, then the matrix is strictly regular -- this follows from the fact that to get a minor you multiply a corresponding submatrix of $L$ by a corresponding submatrix of $U$, and they are non-singular (since non-singularity of triangular matrices is equivalent to the fact that their diagonal elements are not equal to zero).\n",
      "\n",
      "The other way can be proven by **induction**. Suppose that we know that for all $(n-1) \\times (n-1)$ matrices will non-singular minors LU-decomposition exists."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Then, consider the block form\n",
      "$$\n",
      "    A = \\begin{bmatrix}\n",
      "          a & c^{\\top} \\\\\n",
      "          b & D\n",
      "    \\end{bmatrix},\n",
      "$$\n",
      "where $D$ is $(n-1) \\times (n-1)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Then we do \"block elimination\": \n",
      "$$\n",
      "     \\begin{bmatrix}\n",
      "     1 & 0 \\\\\n",
      "     -z & I\n",
      "     \\end{bmatrix}\n",
      "     \\begin{bmatrix}\n",
      "     a & c^{\\top} \\\\\n",
      "     b & D \n",
      "     \\end{bmatrix}=\n",
      "     \\begin{bmatrix}\n",
      "     a & c^{\\top} \\\\\n",
      "     0 & A_1\n",
      "     \\end{bmatrix},\n",
      "$$\n",
      "where $z = \\frac{b}{a}, \\quad A_1 = D - \\frac{1}{a} b c^{\\top}$.\n",
      "We can show that $A_1$ is also strictly regular, thus it has (by induction) the LU-decomposition:  \n",
      "$$\n",
      "   A_1 = L_1 U_1, \n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "And then\n",
      "$$\n",
      "   L = \\begin{bmatrix}\n",
      "    1 & 0 \\\\\n",
      "    z & L_1\n",
      "     \\end{bmatrix}, \\quad \n",
      "     U = \\begin{bmatrix}\n",
      "     a & c^{\\top} \\\\\n",
      "     0 & U_1\n",
      "     \\end{bmatrix}\n",
      "$$\n",
      "we get $A = LU$ and $L$ and $U$ have the necessary triangular structure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## When LU fails\n",
      "What happens, if the matrix is not strictly regular (or the **pivots** in the Gaussian elimination are really small?). There is classical $2 \\times 2$ example of a bad LU decomposition.  The matrix we look at is  \n",
      "$$\n",
      "    A = \\begin{pmatrix}\n",
      "    \\varepsilon & 1 \\\\\n",
      "    1 & 1 \n",
      "    \\end{pmatrix}\n",
      "$$\n",
      "If $\\varepsilon$ is sufficiently small, we **might** fail."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "eps = 1e-13\n",
      "a = [[eps, 1],[1,  1]]\n",
      "a = np.array(a)\n",
      "a0 = a.copy()\n",
      "n = a.shape[0]\n",
      "L = np.zeros((n, n))\n",
      "U = np.zeros((n, n))\n",
      "for k in xrange(n): #Eliminate one row   \n",
      "    L[k, k] = 1\n",
      "    for i in xrange(k+1, n):\n",
      "        L[i, k] = a[i, k] / a[k, k]\n",
      "        for j in xrange(k+1, n):\n",
      "            a[i, j] = a[i, j] - L[i, k] * a[k, j]\n",
      "    for j in xrange(k, n):\n",
      "        U[k, j] = a[k, j]\n",
      "\n",
      "print 'L * U - A:', np.dot(L, U) - a0"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "L * U - A: [[ 0.  0.]\n",
        " [ 0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## The concept of pivoting\n",
      "We can do pivoting, i.e. permute rows and columns to maximize $A_{kk}$ that we divide over.  \n",
      "The simplest but effective strategy is the **row pivoting**: at each step, select the index that is maximal in modulus, and put it onto the diagonal. \n",
      "\n",
      "It gives us the decomposition \n",
      "\n",
      "$$A = P L U,$$\n",
      "where $P$ is a **permutation matrix**.\n",
      "\n",
      "\n",
      "What makes pivoting good?  \n",
      "It is made good by the fact that  \n",
      "\n",
      "$$\n",
      "   | L_{ij}|<1,\n",
      "$$\n",
      "but the elements of $U$ can grow, up to $2^n$! (in practice, this is very rarely encountered).\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Cholesky factorization\n",
      "A very important class of matrices is the class of **symmetric positive definite matrices**. \n",
      "By positive definiteness we mean that the associated **quadratic form**  is always positive\n",
      "$$\n",
      "   (Ax, x) > 0.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In this case, the LU-factorization always exists and moreover, it can be written in the form of **Cholesky factorization**:  \n",
      "$$\n",
      "   A = R R^*\n",
      "$$\n",
      "And we always can select pivots on the diagonal!\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Summary on the LU for dense matrices\n",
      "- Principal submatrices non-singular -- there exists LU\n",
      "- Pivoting is needed to avoid error growth\n",
      "- Complexity is $\\mathcal{O}(n^3)$ for the factorization step (can be speeded by using Strassen ideas) and $\\mathcal{O}(n^2)$ for a solve"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## QR-decomposition\n",
      "The next decomposition: **QR** decomposition. Again from the name it is clear that a matrix is represented as a product  \n",
      "$$\n",
      "    A = Q R, \n",
      "$$\n",
      "where $Q$ is an **orthogonal (unitary)** matrix and $R$ is **upper triangular**.  \n",
      "The matrix sizes: $Q$ is $n \\times m$, $R$ is $m \\times m$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This algorithm plays a crucial role in many problems:\n",
      "- Computing orthogonal bases ior a linear space\n",
      "- Used in the preprocessing step for the SVD\n",
      "- QR-algorithm for the computation of eigenvectors and eigenvalues (one of the 10 most important algorithms of the 20th century) is    based on the QR-decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Theorem \n",
      "Every rectangular $n \\times m$ matrix, $n \\geq m$ matrix has a QR-decomposition. \n",
      "There are several ways to prove it and compute it.\n",
      "\n",
      "- (mathematical) Using the Gram matrices and Cholesky factorization\n",
      "- (geometrical) Using the Gram-Schmidt orthogonalization\n",
      "- (practical) Using Householder/Givens transformations \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Mathematical way\n",
      "$$A = QR,$$\n",
      "then $A^* A = R^* R$, the matrix $A^* A$ is called **Gram matrix**, and its elements are scalar products of the columns of $A$.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "It is simple to show that $A^* A$ is positive definite:\n",
      "$$\n",
      "   (A^* A y, y) = (Ay, Ay)^2 = \\Vert Ay \\Vert  \\geq 0.\n",
      "$$\n",
      "Therefore, $A^* A = R^* R$ always exists.\n",
      "Then the matrix $A R^{-1}$ is orthogonal:  \n",
      "$$\n",
      "   (A R^{-1})^* (AR^{-1}= R^{-*} A^* A R^{-1} = R^{-*} R^* R R^{-1} = I.\n",
      "$$\n",
      "\n",
      "**Gram matrices are not good for numerical stability**!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Let us show that on random and Hilbert matrices :)\n",
      "The Gram-matrix method may lead to the loss of orthogonality."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "n = 40\n",
      "r = 7\n",
      "#a = np.random.randn(n, r)\n",
      "a = [[1.0/(i+j+0.5) for i in xrange(r)] for j in xrange(n)]\n",
      "a = np.array(a)\n",
      "q, Rmat = np.linalg.qr(a)\n",
      "e = np.eye(r)\n",
      "print 'Built-in QR orth', np.linalg.norm(np.dot(q.T, q) - e)\n",
      "gram_matrix = a.T.dot(a)\n",
      "Rmat1 = np.linalg.cholesky(gram_matrix)\n",
      "q1 = np.dot(a, np.linalg.inv(Rmat1.T))\n",
      "print 'Via Gram matrix:', np.linalg.norm(np.dot(q1.T, q1) - e)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Built-in QR orth 1.2649832844e-15\n",
        "Via Gram matrix: 8.23339233173e-05\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Second way: Gram-Schmidt orthogonalization\n",
      "QR-decomposition is a mathematical way of writing down the Gram-Schmidt orthogonalization process.  \n",
      "Given a sequence of vectors $a_1, \\ldots, a_m$ we want to find orthogonal basis $q_1, \\ldots, q_m$ such that every $a_i$ is a linear combination of such vectors.  \n",
      "\n",
      "**Gram-Schmidt:**\n",
      "1. $q_1 := a_1/\\Vert a_1 \\Vert$\n",
      "2. $q_2 := a_2 - (a_2, q_1) q_1, \\quad q_2 := q_2/\\Vert q_2 \\Vert$\n",
      "3. $q_3 := a_3 - (a_3, q_1) q_1 - (a_3, q_2) q_2), \\quad q_2 := q_3/\\Vert q_3 \\Vert$\n",
      "4. And go on\n",
      "Note that the transformation from $Q$ to $A$ has triangular structure, since from the $k$-th vector we subtract only the previous ones."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Gram-Schmidt is unstable\n",
      "Gram-Schmidt can be very unstable (i.e., the produced vectors will be not orthogonal, especially if $q_k$ has small norm).  \n",
      "This is called **loss of orthogonality**.  \n",
      "There is a remedy, called **modified Gram-Schmidt** method. \n",
      "Instead of doing \n",
      "$$q_k := a_k - (a_k, q_1) q_1 - \\ldots - (a_k, q_{k-1}) q_{k-1}$$\n",
      "we do it step-by-step. First we set $q_k := a_k$ and orthogonalize sequentially:\n",
      "$$\n",
      "   q_k := q_k - (q_k, q_1)q_1, \\quad q_k := q_{k} - (q_k,q_2)q_2, \\ldots\n",
      "$$\n",
      "In exact arithmetic, it is the same. In floating point it is absolutely different!\n",
      "\n",
      "Note that the complexity in $\\mathcal{O}(nm^2)$ operations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## QR-decomposition: the (almost) practical way\n",
      "\n",
      "If $A = QR$, then  \n",
      "$$\n",
      "R = Q^* A,\n",
      "$$\n",
      "and we need to find a certain orthogonal matrix $Q$ that brings a matrix into orthogonal form.  \n",
      "For simplicity, we will look for an $n \\times n$ matrix such that\n",
      "$$\n",
      "   Q^* A = \\begin{bmatrix}\n",
      "   * & * & *  \\\\\n",
      "   0 & * & * \\\\\n",
      "   0 & 0 & * \\\\\n",
      "   &0_{(n-m) \\times m}\n",
      "   \\end{bmatrix}\n",
      "$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We will do it column-by-column.  \n",
      "First, we find a Householder matrix $H_1 = (I - 2 uu^{\\top})$ such that (we illustrate on a $4 \\times 3$ matrix)\n",
      "\n",
      "$$\n",
      "   H_1 A = \\begin{bmatrix}\n",
      "    * & * & * \\\\\n",
      "    0 & * & * \\\\\n",
      "    0 & * & * \\\\\n",
      "    0 & * & *\n",
      "   \\end{bmatrix}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Then, \n",
      "$$\n",
      "   H_2 H_1 A = \\begin{bmatrix}\n",
      "    * & * & * \\\\\n",
      "    0 & * & * \\\\\n",
      "    0 & 0 & * \\\\\n",
      "    0 & 0 & *\n",
      "   \\end{bmatrix},\n",
      "$$\n",
      "where\n",
      "$$\n",
      "  H_2 = \\begin{bmatrix}\n",
      "  1 & 0 \\\\\n",
      "  0 & H'_2, \n",
      "  \\end{bmatrix}\n",
      "$$\n",
      "and $H'_2$ is a $3 \\times 3$ Householder matrix."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Finally, \n",
      "$$\n",
      "   H_3 H_2 H_1 A = \\begin{bmatrix}\n",
      "    * & * & * \\\\\n",
      "    0 & * & * \\\\\n",
      "    0 & 0 & * \\\\\n",
      "    0 & 0 & 0\n",
      "   \\end{bmatrix},\n",
      "$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "A simple implementation of the Householder method in Python looks as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Initialization\n",
      "import numpy as np\n",
      "n = 4\n",
      "r = 3\n",
      "a = np.random.randn(n, r)\n",
      "k = 0"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def householder(x):\n",
      "    u = x.copy()\n",
      "    u = u / np.linalg.norm(u)\n",
      "    u[0] = u[0] - 1 #Or plus\n",
      "    u = u / np.linalg.norm(u)\n",
      "    u = np.reshape(u, (-1, 1))\n",
      "    return u\n",
      "\n",
      "\n",
      "x = a[:, k:k+1]\n",
      "u0 = householder(a[k:, k:k+1])\n",
      "u = np.zeros((n, 1))\n",
      "u[k:] = u0\n",
      "H = np.eye(n) - 2 * u.dot(u.T)\n",
      "a = H.T.dot(a)\n",
      "print a\n",
      "k = k + 1\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  1.80358498e+00   7.00578974e-01  -2.47003425e-01]\n",
        " [  8.90118454e-17   1.89515182e+00  -1.56544941e+00]\n",
        " [ -5.01528932e-17  -4.39571199e-17   4.41916097e-01]\n",
        " [ -9.72807504e-17  -3.48320668e-16   0.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## The QR algorithm\n",
      "The QR algorithm (Kublanovskaya and Francis independently proposed it in 1961). Do not **mix** QR algorithm and QR decomposition. \n",
      "QR-decomposition is the representation of a matrix, whereas QR algorithm uses QR decomposition computes the eigenvalues!\n",
      "\n",
      "Computation of the eigenvectors and eigenvalues of a matrix.  \n",
      "\n",
      "\n",
      "- Initialization: $$A_0 := A$$\n",
      "- Iteration step: $$Q_k R_k = A_k, \\quad A_{k+1} = R_k Q_k,$$\n",
      "so we compute the QR-factorization of a matrix, and then multiply them in the opposite order.  \n",
      "Good news: the spectrum of $A_k$ is the same as of $A_0$, and $A_k$ converges to a triangular matrix!  \n",
      "It is too tempting not to implement it :)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "n = 4\n",
      "a = [[1.0/(i + j + 0.5) for i in xrange(n)] for j in xrange(n)]\n",
      "niters = 10\n",
      "for k in xrange(niters):\n",
      "    q, rmat = np.linalg.qr(a)\n",
      "    a = rmat.dot(q)\n",
      "    print 'current a:'\n",
      "    print a\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "current a:\n",
        "[[  2.40047183e+00   1.43485636e-01   4.99605047e-03  -5.56291523e-05]\n",
        " [  1.43485636e-01   3.59286592e-01   1.60534687e-02  -1.94225770e-04]\n",
        " [  4.99605047e-03   1.60534687e-02   1.60692682e-02  -2.80885670e-04]\n",
        " [ -5.56291523e-05  -1.94225770e-04  -2.80885670e-04   2.40684296e-04]]\n",
        "current a:\n",
        "[[  2.41031150e+00   2.09437993e-02   3.18722176e-05   5.45279213e-09]\n",
        " [  2.09437993e-02   3.50196113e-01   6.87806955e-04   1.28079871e-07]\n",
        " [  3.18722176e-05   6.87806955e-04   1.53250849e-02   4.17732654e-06]\n",
        " [  5.45279205e-09   1.28079871e-07   4.17732654e-06   2.35678648e-04]]\n",
        "current a:\n",
        "[[  2.41051991e+00   3.04114601e-03   2.02621961e-07  -5.33227597e-13]\n",
        " [  3.04114601e-03   3.49989111e-01   3.00995528e-05  -8.62074652e-11]\n",
        " [  2.02621961e-07   3.00995528e-05   1.53236760e-02  -6.42429491e-08]\n",
        " [ -5.33147641e-13  -8.62074827e-11  -6.42429491e-08   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052431e+00   4.41545673e-04   1.28806658e-09   1.32059800e-16]\n",
        " [  4.41545673e-04   3.49984720e-01   1.31786000e-06   5.80333420e-14]\n",
        " [  1.28806664e-09   1.31786000e-06   1.53236733e-02   9.88053919e-10]\n",
        " [  5.21260158e-17   5.80510077e-14   9.88053906e-10   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052440e+00   6.41081268e-05   8.18816607e-12  -7.99356474e-17]\n",
        " [  6.41081268e-05   3.49984627e-01   5.77009674e-08  -2.14109052e-17]\n",
        " [  8.18822358e-12   5.77009674e-08   1.53236733e-02  -1.51962427e-11]\n",
        " [ -5.09637195e-21  -3.90911829e-17  -1.51962302e-11   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052440e+00   9.30787458e-06   5.19949264e-14   7.99300814e-17]\n",
        " [  9.30787458e-06   3.49984626e-01   2.52637036e-09  -1.76560777e-17]\n",
        " [  5.20524342e-14   2.52637031e-09   1.53236733e-02   2.33729939e-13]\n",
        " [  4.98273388e-25   2.63237618e-20   2.33717423e-13   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052440e+00   1.35141258e-06   2.73389069e-16  -7.99300126e-17]\n",
        " [  1.35141258e-06   3.49984625e-01   1.10614263e-10   1.76826923e-17]\n",
        " [  3.30896669e-16   1.10614211e-10   1.53236733e-02  -3.60708065e-15]\n",
        " [ -4.87162969e-29  -1.77262591e-23  -3.59456477e-15   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052440e+00   1.96211922e-07  -5.54040645e-17   7.99300027e-17]\n",
        " [  1.96211922e-07   3.49984625e-01   4.84316731e-12  -1.76827548e-17]\n",
        " [  2.10350596e-18   4.84311567e-12   1.53236733e-02   6.78001457e-17]\n",
        " [  4.76300288e-33   1.19367537e-26   5.52842647e-17   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052440e+00   2.84880569e-08  -5.74941943e-17  -7.99300013e-17]\n",
        " [  2.84880568e-08   3.49984625e-01   2.12101875e-13   1.76827614e-17]\n",
        " [  1.33719609e-20   2.12050235e-13   1.53236733e-02  -1.33661508e-17]\n",
        " [ -4.65679822e-37  -8.03813647e-30  -8.50269816e-19   2.35677492e-04]]\n",
        "current a:\n",
        "[[  2.41052440e+00   4.13618795e-09  -5.75074807e-17   7.99300011e-17]\n",
        " [  4.13618792e-09   3.49984625e-01   9.33601458e-15  -1.76827623e-17]\n",
        " [  8.50053870e-23   9.28437503e-15   1.53236733e-02   1.25289581e-17]\n",
        " [  4.55296169e-41   5.41283161e-33   1.30771163e-20   2.35677492e-04]]\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Take home message\n",
      "- LU decomposition, Cholesky, their complexity is $\\mathcal{O}(n^3)$, used to solve dense linear systems\n",
      "- QR decomposition, find orthogonal basis, the basic component for the computation of eigenvalues and eigenvectors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Next time\n",
      "- How do we compute LU factorizations for large-scale problems? \n",
      "- And: the SVD (with some examples)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##### Questions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        /*width:80%;*/\n",
        "        /*margin-left:auto !important;\n",
        "        margin-right:auto;*/\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'Fenix', serif;\n",
        "    }\n",
        "    h3{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "\th4{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "       }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\t   \n",
        "    div.text_cell_render{\n",
        "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 1.2;\n",
        "        font-size: 160%;\n",
        "        /*width:70%;*/\n",
        "        /*margin-left:auto;*/\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\";\n",
        "\t\t\tfont-size: 90%;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 50pt;\n",
        "\t\tline-height: 110%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\t\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 137,
       "text": [
        "<IPython.core.display.HTML at 0x1224ad390>"
       ]
      }
     ],
     "prompt_number": 137
    }
   ],
   "metadata": {}
  }
 ]
}