{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:20191d4ca02935e8f7a483f2b29b613f69c165ae4786983b21ca9e5c238d1efb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Lecture 8: Singular value decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Syllabus\n",
      "**Week 1:** Python intro  \n",
      "**Week 2:** Matrices, vectors, norms, ranks  \n",
      "**Week 3:** Linear systems, eigenvectors, eigenvalues  \n",
      "**Week 4:** Singular value decomposition + test + homework seminar  \n",
      "**Week 5:** Sparse & structured matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Recap of the previous lecture\n",
      "- SVD, best low-rank approximations\n",
      "- Applications  \n",
      "  (Eigenfaces, collaborative filtering, integral equations, latent semantic indexing)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "<img width=40% src=\"svd-preg.jpg\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Today lecture\n",
      "Today we will talk about **sparse matrices**.\n",
      "\n",
      "- Formats: list of lists and compressed sparse row format, relation to sparse graph\n",
      "- Fast matrix-by-vector product\n",
      "- Fast direct solvers for Gaussian elimination"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Why sparse matrices are important\n",
      "\n",
      "- Describe local physical nature\n",
      "- Provide storage reduction and matrix-by-vector product reduction\n",
      "- Describe graphs: $a_{ij} \\ne 0$ if there is an edge between vertex $i$ and vertex $j$. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Sparse matrices are ubiqitous in PDE\n",
      "Consider the simplest partial differential equation (PDE), called **Laplace equation**:  \n",
      "$$\n",
      "   \\Delta T = \\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial y^2} = f.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Discretization\n",
      "$$\\frac{\\partial^2 T}{\\partial x^2} \\approx \\frac{T(x+h) + T(x-h) - 2T(x)}{h^2} + \\mathcal{O}(h^4),$$\n",
      "same for $\\frac{\\partial^2 T}{\\partial y^2},$\n",
      "and we get a linear system.  \n",
      "    First, let us do **one-dimensional case**:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$ \\frac{u_{i+1} + u_{i-1} - 2u_i}{h^2} = f_i,$$ \n",
      "or in the matrix form\n",
      "\n",
      "$$\n",
      "   A u = f,\n",
      "$$\n",
      "and ($n = 5$ illustration)\n",
      "$$\n",
      "   A = -\\frac{1}{h^2}\\begin{pmatrix}\n",
      "   2& -1 & 0 & 0 & 0\\\\\n",
      "   -1 & 2 & -1 & 0 &0 \\\\\n",
      "   0 & -1 & 2& -1 & 0 \\\\\n",
      "   0 & 0 & -1 & 2  &-1\\\\\n",
      "   0 & 0 & 0 & -1 & 2\n",
      "   \\end{pmatrix}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The matrix is **triadiagonal** and **sparse**  \n",
      "(and also **Toeplitz**: all elements on the diagonal are the same)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Block structure in 2D\n",
      "In two dimensions, we get equation of the form  \n",
      "$$\\frac{4u_{ij} -u_{(i-1)j} - u_{(i+1)j} - u_{i(j-1)}-u_{i(j+1)}}{h^2} = f_{ij},$$\n",
      "or in the **Kronecker product form**  \n",
      "\n",
      "$$\\Delta_2 = \\Delta_1 \\otimes I + I \\otimes \\Delta_1,$$\n",
      "where $\\Delta_1$ is a 1D Laplacian, and $\\otimes$ is a **Kronecker product** of matrices.  \n",
      "For matrices $A$ and $B$ its Kronecker product is defined as a block matrix of the form \n",
      "$$\n",
      "   [a_{ij} B]\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "$$\n",
      "   A = -\\frac{1}{h^2}\\begin{pmatrix}\n",
      "   \\Delta_1 + 2I & -I & 0 & 0 & 0\\\\\n",
      "   -I & \\Delta_1 + 2I  & -I & 0 &0 \\\\\n",
      "   0 & -I & \\Delta_1 + 2I & -I & 0 \\\\\n",
      "   0 & 0 & -I & \\Delta_1 + 2I   &-I\\\\\n",
      "   0 & 0 & 0 & -I & \\Delta_1 + 2I \n",
      "   \\end{pmatrix}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create this matrix using **scipy.sparse** package"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.sparse\n",
      "from scipy.sparse import csc_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "n = 20\n",
      "ex = np.ones(n);\n",
      "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "e = sp.sparse.eye(n)\n",
      "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
      "A = csc_matrix(A)\n",
      "plt.spy(A, aspect='equal', marker='.', markersize=1)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can now solve the system  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.sparse\n",
      "import scipy.sparse.linalg\n",
      "from scipy.sparse import csc_matrix, csr_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "n = 50\n",
      "ex = np.ones(n);\n",
      "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "e = sp.sparse.eye(n)\n",
      "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
      "A = csr_matrix(A)\n",
      "rhs = np.ones(n * n)\n",
      "sol = sp.sparse.linalg.spsolve(A, rhs)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "And plot the solution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111, projection='3d')\n",
      "t = np.linspace(0, 1, n)\n",
      "x, y = np.meshgrid(t, t)\n",
      "sol = np.reshape(sol, (n, n))\n",
      "ax.plot_wireframe(x, y, -sol)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## How to store a sparse matrix\n",
      "At first glance it is easy: you can use the **coordinate format** as\n",
      "```\n",
      "   (i, j, value)\n",
      "```\n",
      "i.e. store two integer arrays and one real array.\n",
      "This is not optimal.  \n",
      "And how to multiply a matrix by vector?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Compressed sparse row\n",
      "A matrix is stored as 3 different arrays: \n",
      "```\n",
      "ia, ja, sa\n",
      "```\n",
      "where:\n",
      "\n",
      "- **ia** is an integer array of length $n+1$ \n",
      "- **ja** is an integer array of length **nnz** \n",
      "-  **sa** is an real-value array of length **nnz**\n",
      "- **nnz** is the total number of non-zeros for the matrix\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Idea behind CSR.\n",
      "- For each row $i$ we store the column number of the non-zeros (and their) values\n",
      "- We stack this all together into **ja** and **sa** arrays\n",
      "- We save the location of the **first non-zero element** in each row"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "## CSR helps for matrix-by-vector product as well\n",
      "```\n",
      "   for i in xrange(n):\n",
      "       for k in xrange(ia(i):ia(i+1)-1):\n",
      "           y(i) += sa(k) * x(ja(k))\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Let us do a short timing test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.sparse\n",
      "import scipy.sparse.linalg\n",
      "from scipy.sparse import csc_matrix, csr_matrix, coo_matrix\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "n = 20\n",
      "ex = np.ones(n);\n",
      "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "e = sp.sparse.eye(n)\n",
      "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
      "A = csr_matrix(A)\n",
      "rhs = np.ones(n * n)\n",
      "B = coo_matrix(A)\n",
      "%timeit A.dot(rhs)\n",
      "%timeit B.dot(rhs)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "As you see, **CSR** is faster, and for more **unstructured patterns** the gain will be larger."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Sparse matrices and efficiency\n",
      "Sparse matrix give complexity reduction.  \n",
      "But they are **not very good** for parallel implementation.  \n",
      "And they do not give maximal efficiency due to **random data access**.  \n",
      "Typically, peak efficiency of $10-15$ is considered good.  \n",
      "We can measure peak efficiency of an ordinary dot product:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import time\n",
      "n = 1000\n",
      "a = np.random.randn(n, n)\n",
      "v = np.random.randn(n)\n",
      "t = time.time()\n",
      "np.dot(a, v)\n",
      "t = time.time() - t\n",
      "print 'Efficiency:', ((2 * n ** 2)/t) / 10 ** 9, 'Gflops'"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "And for the sparse one:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 1000\n",
      "ex = np.ones(n);\n",
      "a = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "rhs = np.random.randn(n)\n",
      "t = time.time()\n",
      "a.dot(rhs)\n",
      "t = time.time() - t\n",
      "print 'Efficiency:', (3 * n) / t / 10 ** 9, 'Gflops'"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## How to solve linear systems?\n",
      "How to solve linear systems with sparse matrices?  \n",
      "The **direct methods** use **sparse Gaussian elimination**, i.e.  \n",
      "they eliminate variables while trying to keep  \n",
      "the matrix as sparse as possible. And often, the inverse of a sparse matrix is **not sparse**\n",
      "(but $L$ and $U$ factors can be). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 7\n",
      "ex = np.ones(n);\n",
      "a = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "a = a.todense()\n",
      "b = np.array(np.linalg.inv(a))\n",
      "print b"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The L and U factors are typically better"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p, l, u = scipy.linalg.lu(a)\n",
      "print l"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "However, for a 2D case everything is much worser:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 20\n",
      "ex = np.ones(n);\n",
      "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "e = sp.sparse.eye(n)\n",
      "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
      "A = csc_matrix(A)\n",
      "T = scipy.sparse.linalg.spilu(A)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.spy(T.L, marker='.', markersize=0.4)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "For two-dimensional case the number of nonzeros in the L factor grows as $\\mathcal{O}(N^{3/2})$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Sparse matrices and graph ordering\n",
      "The number of non-zeros in LU decomposition has a deep connection to the graph theory.  \n",
      "(I.e., there is an edge between $(i, j)$ if $a_{ij} \\ne 0$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "n = 10\n",
      "ex = np.ones(n);\n",
      "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "e = sp.sparse.eye(n)\n",
      "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
      "A = csc_matrix(A)\n",
      "G = nx.Graph(A)\n",
      "nx.draw(G, pos=nx.spring_layout(G), node_size=10)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Strategies for elimination\n",
      "The reordering that minimizes the fill-in is important, so we can you **graph theory** to find one.\n",
      "\n",
      "- **Minimum degree ordering** - order by the degree of the vertex\n",
      "- **Cuthill\u2013McKee algorithm** (and reverse Cuthill-McKee) -- order for a small bandwidth\n",
      "- **Nested dissection**: split the graph into two with minimal number of vertices on the separator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "from networkx.utils import reverse_cuthill_mckee_ordering, cuthill_mckee_ordering\n",
      "n = 10\n",
      "ex = np.ones(n);\n",
      "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
      "e = sp.sparse.eye(n)\n",
      "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
      "A = csc_matrix(A)\n",
      "G = nx.Graph(A)\n",
      "#rcm = list(reverse_cuthill_mckee_ordering(G))\n",
      "rcm = list(reverse_cuthill_mckee_ordering(G))\n",
      "A1 = A[rcm, :][:, rcm]\n",
      "#plt.spy(A1, marker='.', markersize=0.5)\n",
      "p, L, U = scipy.linalg.lu(A1.todense())\n",
      "plt.spy(L, marker='.', markersize=0.8)\n",
      "#nx.draw(G, pos=nx.spring_layout(G), node_size=10)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The most efficient one is nested dissection algorithm, which finds the ordering recursively by computing the **separator**. No good implementation was found by me at the moment."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Florida sparse matrix collection\n",
      "[Florida sparse matrix collection](http://www.cise.ufl.edu/research/sparse/matrices/) which contains all sorts of matrices for different applications.  It also allows for finding test matrices as well! We can have a look."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('<iframe src=http://yifanhu.net/GALLERY/GRAPHS/search.html width=700 height=450></iframe>')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Test some\n",
      "Let us check some sparse matrix (and its LU)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = 'crystm02.mat'\n",
      "!wget http://www.cise.ufl.edu/research/sparse/mat/Boeing/$fname"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.io import loadmat\n",
      "import scipy.sparse\n",
      "q = loadmat(fname)\n",
      "print q\n",
      "mat = q['Problem']['A'][0, 0]\n",
      "T = scipy.sparse.linalg.splu(mat)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Compute its LU\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "plt.spy(T.L, markersize=0.1)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Take home message\n",
      "- CSR format for storage\n",
      "- Sparse matrices & graphs ordering\n",
      "- Ordering is important for LU fill-in"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Next lecture\n",
      "- Structured matrices: the idea\n",
      "- Circulant matrices and the Fast Fourier Transform\n",
      "- Toeplitz matrices and shift-invariant structure\n",
      "- Displacement structure, solution of linear systems with Toeplitz matrices\n",
      "- Toeplitz and low-rank matrices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##### Questions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        /*width:80%;*/\n",
        "        /*margin-left:auto !important;\n",
        "        margin-right:auto;*/\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'Fenix', serif;\n",
        "    }\n",
        "    h3{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "\th4{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "       }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\t   \n",
        "    div.text_cell_render{\n",
        "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 1.2;\n",
        "        font-size: 160%;\n",
        "        /*width:70%;*/\n",
        "        /*margin-left:auto;*/\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\";\n",
        "\t\t\tfont-size: 90%;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 50pt;\n",
        "\t\tline-height: 110%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\t\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "<IPython.core.display.HTML at 0x1163ad4d0>"
       ]
      }
     ],
     "prompt_number": 134
    }
   ],
   "metadata": {}
  }
 ]
}