{
 "metadata": {
  "name": "",
  "signature": "sha256:0e8689621afaff3b770d0c01af62ee46fcf2d3f998080455ea9a57d0ed3cafbe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Lecture 11: Matrix functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Syllabus\n",
      "**Week 1:** Python intro  \n",
      "**Week 2:** Matrices, vectors, norms, ranks  \n",
      "**Week 3:** Linear systems, eigenvectors, eigenvalues  \n",
      "**Week 4:** Singular value decomposition + test + homework seminar  \n",
      "**Week 5:** Sparse & structured matrices  \n",
      "**Week 6:** Iterative methods, preconditioners, matrix functions  \n",
      "**Week 7:** Test week  \n",
      "**Week 8:** App Period  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Recap of the previous lecture\n",
      "- Concept of iterative methods  \n",
      "- Richardson iteration, Chebyshev acceleration  \n",
      "- Idea of Krylov methods  \n",
      "- Conjugate gradient methods for symmetric positive definite matrices\n",
      "- Generalized minimal residual methods\n",
      "- The Zoo of iterative methods: BiCGStab, QMR, IDR, ...\n",
      "- The idea of preconditioners\n",
      "- Jacobi/Gauss-Seidel methods Incomplete ILU"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Today lecture\n",
      "Today we will talk about **matrix functions**. \n",
      "- What is a matrix function\n",
      "- Matrix exponential\n",
      "- (Some) applications\n",
      "\n",
      "Book to read: [Nick Higham, Functions of matrices](http://www.google.ru/books?hl=ru&lr=&id=2Wz_zVUEwPkC&oi=fnd&pg=PR3&dq=Higham+matrix+function&ots=pTt6fpLGRX&sig=DgUuX-SpBZGin8CFUo-4MYnOcHE&redir_esc=y#v=onepage&q=Higham%20matrix%20function&f=false)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Where matrix functions come from\n",
      "\n",
      "- Solution of PDEs and ODEs (matrix exponent, matrix sine function, matrix cosine function, square root,  \n",
      "  sign function)\n",
      "- Matrix exponent has application in localized PageRank, graph centrality\n",
      "- Quantum physics\n",
      "- Inverse is matrix function as well! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## What is a matrix function?\n",
      "A matrix function is a function of a matrix. A matrix function **is not** a function, applied to the elements!\n",
      "\n",
      "I.e., $B = \\sqrt{A}$ **does not mean** that $B_{ij} = \\sqrt{A}_{ij}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.linalg as sla \n",
      "\n",
      "A = 2 * np.eye(2)\n",
      "A = np.array([[4, 3], [4, 4]])\n",
      "sla.funm(A, lambda x: np.sqrt(x) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The simplest matrix function: matrix polynomial\n",
      "\n",
      "It is very easy to define a matrix polynomial as  \n",
      "$$\n",
      " P(A) = \\sum_{k=0}^n c_k A^k.\n",
      "$$\n",
      "**Side-note:** [Hamilton-Cayley theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem) states that $F(A) = 0$ where $F(\\lambda) = \\det(A - \\lambda I)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Matrix polynomials as building blocks\n",
      "We can define a function of the matrix by **Taylor series**:  \n",
      "$$\n",
      "   f(A) = \\sum_{k=0}^{\\infty} c_k A^k.\n",
      "$$\n",
      "The convergence is understood as the convergence in some **matrix norm**.  \n",
      "Example of such series is the **Neumann series**  \n",
      "$$\n",
      "  (I - F)^{-1} = \\sum_{k=0}^{\\infty} F^k,\n",
      "$$\n",
      "which is well defined for $\\rho(A) < 1$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Matrix exponential series\n",
      "The most well-known matrix function is **matrix exponential**. In the scalar case,  \n",
      "$$\n",
      "   e^x = 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\ldots = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!},\n",
      "$$\n",
      "and it directly translates to the matrix case:  \n",
      "$$\n",
      "    e^A = \\sum_{k=0}^{\\infty} \\frac{A^k}{k!},\n",
      "$$\n",
      "the series that always converges (why?)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Why matrix exponential is important\n",
      "A **lot of** practical problems are reduced to a system of linear ODEs of the form  \n",
      "$$\n",
      "   \\frac{dy}{dt} = Ay, \\quad y(0) = y_0.\n",
      "$$\n",
      "The formal solution is given by $y(t) = e^{At} y_0$, so if we know  \n",
      "$e^{At}$ (or can compute matrix-by-vector product fast) there is a big gain over the  \n",
      "time-stepping schemes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How to compute matrix functions?\n",
      "\n",
      "See [C. Van Loan, C. Moler, Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later](http://www.cs.cornell.edu/cv/researchpdf/19ways+.pdf)\n",
      "\n",
      "The simplest way is to diagonalize the matrix:  \n",
      "$$\n",
      "  A = S \\Lambda S^{-1}.\n",
      "$$\n",
      "where the columns of $S$ are **eigenvectors** of the matrix $A$,  then  \n",
      "\n",
      "$$\n",
      "   F(A) = S F(\\Lambda) S^{-1}.\n",
      "$$\n",
      "Problem: **diagonalization can be unstable!** (and not every matrix is diagonalizable)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us look how matrices are diagonalizable:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "eps = 1e-8\n",
      "p = 5\n",
      "a = np.eye(p)\n",
      "for i in xrange(p-1):\n",
      "    a[i, i+1] = 1\n",
      "    \n",
      "a[p-1, 0] = eps\n",
      "a = np.array(a)\n",
      "val, vec = np.linalg.eig(a)\n",
      "print np.linalg.norm(a - vec.dot(np.diag(val)).dot(np.linalg.inv(vec)))\n",
      "#print 'S * D * S^{-1}:' \n",
      "#print vec.dot(np.diag(val)).dot(np.linalg.inv(vec))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can compute a function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "eps = 1e-4\n",
      "p = 2\n",
      "a = np.eye(p)\n",
      "for i in xrange(p-1):\n",
      "    a[i, i+1] = 1\n",
      "    \n",
      "a[p-1, 0] = eps\n",
      "a = np.array(a)\n",
      "val, vec = np.linalg.eig(a)\n",
      "print np.linalg.norm(a - vec.dot(np.diag(val)).dot(np.linalg.inv(vec)))\n",
      "\n",
      "fun = lambda x: np.exp(x)\n",
      "\n",
      "#Using diagonalization\n",
      "fun_diag = vec.dot(np.diag(fun(val))).dot(np.linalg.inv(vec))\n",
      "\n",
      "\n",
      "#Using Schur\n",
      "import scipy\n",
      "fun_m = scipy.linalg.expm(a)\n",
      "np.linalg.norm(fun_m - fun_diag)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How funm function works\n",
      "The exponential of a matrix is a special function, so there are special methods for its computation.  For a general function,  \n",
      "there is a beautiful **Schur-Parlett algorithm**, which is based on the **Schur theorem**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Schur-Parlett algorithm\n",
      "\n",
      "Given a matrix $A$ we want to compute $F(A)$, and we only can evaluate $F$ at **scalar points**.  \n",
      "First, we reduce $A$ to the **triangular form** as  \n",
      "$$\n",
      "   A = U T U^*.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Therefore,  $F(A)=U F(T) U^*$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Computing functions of triangular matrices\n",
      "We know values on the diagonals:  \n",
      "and $$F_{ii} = F(T_{ii}),$$\n",
      "and also we know that\n",
      "$$F T = T F,$$\n",
      "and we get\n",
      "\n",
      "$$f_{ii} = t_{ij} \\frac{f_{ii} - f_{jj}}{t_{ii} - t_{jj}} + \\sum_{k=i+1}^{j-1} \\frac{f_{ik} t_{kj} - t_{ki}f_{kj}}{t_{ii} - t_{jj}}.$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pade approximations\n",
      "Matrix exponential is well approximated by **rational function**:  \n",
      "\n",
      "$$\\exp(x) \\approx \\frac{p(x)}{q(x)},$$\n",
      "where $p(x)$ and $q(x)$ are polynomials\n",
      "and computation of a rational function of a matrix is reduced to **matrix-matrix products** and **matrix inversions**.  \n",
      "The rational form is also very useful when only a product of a matrix exponential by vector is needed, since  \n",
      "evaluation reduces to **matrix-by-vector products** and **linear systems solvers**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A short demo on Pade approximation via **sympy** package"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sympy.mpmath\n",
      "from sympy.mpmath import pade, taylor, polyval\n",
      "import matplotlib.pyplot as plt\n",
      "x = np.linspace(0, 1, 128)\n",
      "a = taylor(sympy.mpmath.exp, 0, 100)\n",
      "p, q = pade(a, 5, 5)\n",
      "plt.semilogy(polyval(p[::-1], x)/polyval(q[::-1], x) - np.exp(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Application to graph centrality\n",
      "\n",
      "One of the recent application is the computation. This example was taken from [here](http://nbviewer.ipython.org/github/sdrelton/matrix_function_notebooks/blob/master/TheMatrixExponential.ipynb).\n",
      "Take the following network.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "Adj = np.array([[0, 1, 1, 0, 0, 0], \n",
      "                [1, 0, 1, 1, 1, 0], \n",
      "                [1, 1, 0, 0, 0, 0], \n",
      "                [0, 1, 0, 0, 0, 1], \n",
      "                [0, 1, 0, 0, 0, 0],\n",
      "                [0, 0, 0, 1, 0, 0]])\n",
      "\n",
      "G = nx.from_numpy_matrix(Adj)\n",
      "nx.draw(G, node_color='y', node_size=1000, with_labels=True )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One measure of the importance of each node is its <b>centrality</b>.\n",
      "We can count the number of paths of different lengths from $i$ to $i$,  \n",
      "and add them up to get **centrality** of the node\n",
      "$$c(i) = \\alpha_1 A_{ii} + \\alpha_2 A^2_{ii} + \\alpha_3 A^3_{ii} + \\cdots,$$\n",
      "where the coefficients $\\alpha_k$ remain to be chosen.  \n",
      "With $\\alpha_k = \\frac{1}{k!}$ we get  \n",
      "$$\n",
      "    c = \\mathrm{diag}(\\exp(A))\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centralities = np.diag(sla.expm(np.array(Adj, dtype=np.double)))\n",
      "nodeorder = np.argsort(centralities)[::-1]\n",
      "\n",
      "print np.array([nodeorder, centralities[nodeorder]])\n",
      "\n",
      "# Note: This is already built into networkx using the following command\n",
      "# print nx.communicability_centrality_exp(G)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Some other matrix functions\n",
      "\n",
      "- Sign function: $F(A) = \\mathrm{sign}(A)$ (no Taylor series), used for spectrum partititioning problems.  \n",
      "  Iteration to compute sign-function: $$A_{k+1} = \\frac{1}{2} (A_k + A^{-1}_k), A_0 = A$$\n",
      "- Cosine/sine functions, used to solve $$\\frac{d^2 y}{dt^2} = A y$$\n",
      "- Square root $\\sqrt{A}$, used to solve Lyapunov equations  \n",
      "    $$A X + X A^{\\top} = B,$$\n",
      "     and Lyapunov equation is used in control theory, model order reduction and many other things."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Take home message\n",
      "- Matrix exponential\n",
      "- Schur-Parlett\n",
      "- Pade approximation\n",
      "- Graphs & PDEs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Next lecture\n",
      "We are done!  \n",
      "Friday - homework seminar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Questions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        /*width:80%;*/\n",
        "        /*margin-left:auto !important;\n",
        "        margin-right:auto;*/\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'Fenix', serif;\n",
        "    }\n",
        "    h3{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "\th4{\n",
        "\t\tfont-family: 'Fenix', serif;\n",
        "       }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\t   \n",
        "    div.text_cell_render{\n",
        "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 1.2;\n",
        "        font-size: 160%;\n",
        "        /*width:70%;*/\n",
        "        /*margin-left:auto;*/\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\";\n",
        "\t\t\tfont-size: 90%;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 50pt;\n",
        "\t\tline-height: 110%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\t\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    li {\n",
        "        line-height: 110%;\n",
        "    }\n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "<IPython.core.display.HTML at 0x1109c5610>"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}